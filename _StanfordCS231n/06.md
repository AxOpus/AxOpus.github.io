---
layout: pagecollection
title: 06 - Training Convolutional Neural Networks (Part 1)
collection: StanfordCS231n
---
{% include JB/setup %}

## Overview
This lecture largely covers general techniques for training neural networks. It covers activation function selection, data pre-processing, weight initialisation, batch normalisation, babysitting the learning process, and hyperparameter optimisation.

## Summary
Activation function: _ReLU_

Data pre-processing: _for images, subtract mean_

Weight initialisation: _use Xavier init (or He)_

Batch normalisation: _Use it_

Hyperparameter optimisation: _random sample hyperparameters_


## Additional material

- [Neural nets 1](http://cs231n.github.io/neural-networks-1/)
- [Neural nets 2](http://cs231n.github.io/neural-networks-2/)
- [Neural nets 3](http://cs231n.github.io/neural-networks-3/)