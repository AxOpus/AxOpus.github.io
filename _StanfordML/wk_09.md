---
layout: pagecollection
title: Week 9 - Density Estimation and Recommender Systems
collection: StanfordML
---
{% include JB/setup %}

## Density estimation
We might want to estimate whether a new example is anomalous. We can do this by defining whether $$p(\mathbf{x}) < \epsilon$$, where $$\epsilon$$ is some some probability. This could be defined using a Gaussian distribution, where we would expect our feature vectors to be normally distributed. We assume that each feature is independently normally distributed: $$\prod_{j=1}^{n}p(x; \mu_{j}, \sigma_{j}^{2})$$.

## Anomaly detection vs. Supervised learning
Anomaly detection is usually used when:
- Very small number of positive examples ($$y = 1$$).
- Large number of negative examples ($$y = 0$$).
- Many different 'types' of anomalies which makes it hard for a learning algorithm to learn what an anomaly is, and makes predicting future anomalies difficult.
- Examples: Fraud detection; Manufacturing; and monitoring machines in a data centre.

Supervised learning is usually used when:
- Large number of positive and negative examples.
- Enough positive examples to identify what a future positive example may look like.
- Examples: Email spam classification; Weather prediction; and Cancer classification.

## Recommender Systems
Suppose we have a set of users and a set of films, along with each user's rating for each film. Additionally, suppose we also have features for each film e.g. romance, car-chases, action, etc. We can then use linear regression to obtain a weight vector for each user, which we can then use to estimate what their likely rating will be for an unseen film. We can train the system by using linear regression.

Suppose we do not know the weights for each feature of each film.




















